# Example configuration file for an LTLZinc problem.

# [Mandatory] Mode of the task:
#   sequential: Generate a single task with samples composed of traces of images.
#   sequential_positive_only: same as sequential, but only generate traces satisfying the specification.
#   incremental: Generate an incremental collection of tasks. Each task is a collection of non-temporal samples which can be shuffled.
mode: sequential

# [Mandatory] Target length. For sequential/sequential_positive_only is the length of each sample. For incremental is the number of tasks.
#   Can be a fixed value (int), or a [min, max] pair (not for incremental mode). In the latter case, traces will have a random length between min and max.
length: 10 # [5, 10]

# [Mandatory] Dataset splits. Each name is associated with a data path and the number of samples to generate. For sequence/sequence_positive_only, this corresponds to the total number of samples, for incremental, this is the number of samples for a single task.
splits:
  train: {path: "data/train", samples: 80}
  val:   {path: "data/test", samples: 10}
  test:  {path: "data/test", samples: 10}
  test_ood: {path: "data/test", samples: 10} # Example for out-of-distribution experiment.
  # domain_adaptation: {path: "data/domain_adaptation", samples: 10} # Another example. It is possible to specify arbitrarily many splits.


# [Optional] Prefix code for all the generated MiniZinc programs. It can contain included libraries, additional constraints, helper functions, etc.
minizinc_prefix: |
  include "all_equal.mzn";
  
  var bool odd; % predicate defined in the prefix. 
  enum ternary_t = {a, b, c};
  var ternary_t: mod3;
  
  constraint odd <-> X mod 2 = 1;
  constraint mod3 = a <-> C mod 3 = 0;
  constraint mod3 = b <-> C mod 3 = 1;
  constraint mod3 = c <-> C mod 3 = 2;

# [Mandatory] Predicate dictionary. It maps symbolic names (e.g. p, q) to MiniZinc constraints. Placeholders (e.g., A,B,C) will be syntactically replaced.
#   This dictionary can also contain predicates which do not appear in the formula (orphan predicates). For these, variables CANNOT be placeholders and must be instead ground variables from the "domains" section.
predicates:
  "p(A,B,C)": "A + B = C" # minizinc syntax. Variables here will be syntactically replaced with those from the formula.
  "q(A,B,C)": "all_equal([A,B,C])" # "normal" predicate, A,B,C are placeholder variables which will be replaced according to the temporal formula.
  # "r(X)": "X < 5" # This is an orphan predicate. X must be a ground variable appearing in the domain association.
  "odd": null # Predicate of arity = 0 manually defined in  minizinc_prefix. Useful for concept-based learning and reasoning. It will be annotated, whether or not it appears in the temporal specification.


# [Mandatory] LTL formula. It must be specified in flloat (https://github.com/whitemech/flloat) syntax.
#   Predicate names will be replaced according to the predicate dictionary (place-holders, A,B,C, will be replaced with variables, X,Y,Z).
formula: "p(X,Y,Z) & X q(T,U,V) & X X q(X,Y,Z)"

# [Mandatory] Data types. If dictionaries, they associate each value to the path containing image samples. When defined as lists, they correspond to symbolic variables with no perceptual counterpart (e.g., output variables).
#   A data type can be integer, or an enumeration (strings). Enumerations will be sorted lexicographically, regardless of the order they appear here (e.g. automobile < bird < cat < dog).
#   Different data types can associate the same value to different image samples (e.g. 0 -> mnist/0, and 0 -> svhn/0), or be composed of different collections of values (e.g. mnist_05 = {0,1,2,3,4,5}, mnist_69 = {6,7,8,9}).
#   This feature allows to easily define out-of-distribution or domain-adaptation splits.
#   NOTE: to avoid MiniZinc errors, each enumeration is defined as a subset of "global_enum_t" type. *Do not* define a type with this name!
types:
  mnist_t:
    0: "mnist/0"
    1: "mnist/1"
    2: "mnist/2"
    3: "mnist/3"
    4: "mnist/4"
    5: "mnist/5"
    6: "mnist/6"
    7: "mnist/7"
    8: "mnist/8"
    9: "mnist/9"
  fmnist_t:
    bag: "fmnist/bag"
    boot: "fmnist/boot"
    coat: "fmnist/coat"
    dress: "fmnist/dress"
    pullover: "fmnist/pullover"
    sandal: "fmnist/sandal"
    shirt: "fmnist/shirt"
    sneaker: "fmnist/sneaker"
    top: "fmnist/top"
    trouser: "fmnist/trouser"

  # You can define other domains with subsets of variables, for out-of-distribution experiments.
  fmnist_05_t: # You can also change the path for each class (e.g. fmnist05/bag) to provide disjoint images for domain adaptation experiments.
    bag: "fmnist/bag"
    boot: "fmnist/boot"
    coat: "fmnist/coat"
    dress: "fmnist/dress"
    pullover: "fmnist/pullover"

  decimal_t: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] #  Domain for symbolic variables.

# [Mandatory] Domain association for each variable appearing in the LTL formula. If it is mapping {variable: type}, every split will use the specified type.
#   If it is a mapping {variable: dict}, it will assign a different type for each split. This can be useful for out-of-distribution and domain-adaptation experiments.
#   NOTE: Either manually add every entry defined in "splits", or add a "default" entry to cover unspecified splits.
domains:
  X: mnist_t
  Y: mnist_t
  Z: mnist_t
  T: fmnist_t # T will always be of type "fmnist_t".
  U:
    default: fmnist_05_t # Every split (except test_ood) will define U as type "fmnist_05_t".
    test_ood: fmnist_t # Out-of-distribution test set split will define U as type "fmnist_t".
  V: fmnist_t
  mod3: ternary_t  # Defined in prefix. These values will NOT be added to global_enum_t, therefore it will not be possible to compare them to other domains.

# [Mandatory] Mapping between formula variables and image streams. This allows to multiplex variables at different time-steps.
#   Streams can optionally be annotated with "modes". Input mode: "+" (default), Output mode: "-".
#   These annotations do not affect the generation pipeline, but can be used to tell your agent which variables depend on the others.
streams: # In this example there is a 1-to-1 mapping between variables and streams. The agent sees 6 streams of images
  X: xx # Mapped to (img_xx, var_xx, direction: input) in csv annotations.
  Y: yy
  Z: -zz # This is an output stream, mapped to (img_zz, var_zz, direction: output) in csv_annotations.
  T: +tt # Explicit input, same as "tt".
  U: uu
  V: -vv
#streams: # In this different example, the agent sees 3 streams of images, but their role changes over time.
#   (e.g. In every state where there is a constraint on X, the agent will receive an image for X,
#    in every state where there is a constraint on T, the agent will receive an image for T,
#    in a state where neither X nor T are relevant, the generator will choose to present either image randomly).
#  X: str1
#  Y: str2
#  Z: str3
#  T: str1
#  U: str2
#  Z: str3
# NOTE: The generator will raise an error if there is stream ambiguity at some time-step (e.g. if it encounters a state which depends both on the value of X and Z).


# [Optional] Perform look-ahead and try to avoid being trapped in sink states (accepting or rejecting), and self loops.
#   If defined, all three strategies must be defined.
#   False: next state will be uniformly sampled.
#   True: next state will be uniformly sampled, after removing every accepting/rejecting sink state from the candidates.
#   linear: rate: let t be the number of times an accepting/rejecting absorbing state has been a potential successor so far, then sample absorbing states with probability rate * t, and every other state uniformly.
#   exponential: rate: like the linear case, but absorbing states are sampled with 1 - e^(-rate * t) probability.
avoid_states:
  accepting_sinks: False
  rejecting_sinks: { "exponential": 1e-3 }
  self_loops: { "linear": 1e-1 }


# [Optional] Upon entering an absorbing state, prematurely truncate the sequence (e.g., because new samples would be irrelevant for learning purposes).
truncate_on_sink:
  accepting: True
  rejecting: False

# [Optional] In case of orphan predicates (predicates defined in "predicates", but not appearing in "formula"), force specific truth values to be observed along the sequence. Possible values: [positive, negative, both]
guarantee_constraint_sampling: positive

# [Optional] The modality in which orphan predicates should appear. At each time step, at most ONE orphan will be selected, in a way in which the entire sequence overall satisfies one of the following criteria:
#   strict_f: guarantee that eventually each orphan is encountered (behaves like a new formula: "old_formula & F p_0 & F p_1 & ... & F p_n", with p_i orphans, without incurring in an exponential blow-up).
#   best_f: guarantee that eventually the largest number of orphans is encountered.
#   strict_g: guarantee that in every time step, at least one orphan is encountered (behaves like "old_formula & G(p_0 | p_1 | ... | p_n)".
#   best_g: guarantee that at least one orphan is encountered for as many time steps as possible.
guarantee_mode: best_f

# [Optional, incremental mode only] Frequency of samples in incremental mode which satisfy guarantee_mode. Can be "once" or a percentage (0.0 <= p <= 1.0).
#   If "once", at least one sample (for each dataset split) will satisfy the chosen guarantee_mode, otherwise p * total will contain orphan guarantees and (1 - p) * total will be unconstrained.
incremental_guarantee_ratio: once #"once" # ["once", p]

# [Optional] Random seed for reproducibility. It can be an integer or a list of integers. In the latter case, multiple datasets will be generated with different random seeds (each in a subfolder of the path specified in the "splits" field).
#   IMPORTANT: Due to a bug in the flloat library, a generated dataset will not be 100% reproducible,
#   because multiple equivalent automata can be generated from the same formula during different executions, and it is not possible to deterministically fix one.
seed: 12345 # [0, 12345, 67890, 88888]